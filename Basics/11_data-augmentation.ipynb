{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Data Augmentation is a technique to artificially increase the size of the training set by applying transformations to the original images. This is a very useful technique to improve the performance of deep learning models, especially when the training set is not large enough to train a large model. For example, in the case of image classification, we can apply transformations such as rotation, translation, scaling, flipping, etc. to the original images to generate new images. In this notebook, we will see how to apply data augmentation to the CIFAR-10 dataset.\n",
    "\n",
    "But it is important to understand that augmentation is not done to make the dataset larger, but to make the model more robust. So essentially the next batch to be processed in augmented on the CPU while the current batch is being processed on the GPU. This is done to make the model more robust and generalize better. We should introduce randomness in the augmentation process and not make it deterministic.\n",
    "\n",
    "You have to be careful that the data augmentation doesnt destroy the label of the image.\n",
    "\n",
    "Many a times data augmentation makes it really diffcult for the model to learn, due to the introduction of a lot of variety in data. So in addition to L2, Dropout data augmentation is also a good way to regularize the model, to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jay/anaconda3/envs/tf/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Configure GPU memory growth to be dynamic instead of allocating all memory at once\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    \"cifar10\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,  # will return tuple (img, label) otherwise dict\n",
    "    with_info=True,  # able to get info about dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\"\"\"\n",
    "augment() function is applied to (image, label) pairs. \n",
    "\n",
    "Augmentation is done because it helps the model to learn better. \n",
    "For example, if you want to classify a dog, you want your model to be robust to \n",
    "different angles, positions, lighting conditions etc. So, you can artificially\n",
    "introduce those variations in your dataset by applying random transformations to your images,\n",
    "like flipping, rotating, changing brightness, etc. This helps the model to get trained on\n",
    "different variations of the same image and thus be robust to them.\n",
    "\n",
    "In the below code, we are doing the following augmentation:\n",
    "1. Resize the images to a bigger height and width.\n",
    "2. Convert some images to grayscale randomly.\n",
    "3. Introduce random brightness and contrast to the images.\n",
    "4. Flip the images horizontally randomly.\n",
    "\n",
    "\"\"\"\n",
    "def augment(image, label):\n",
    "    # If we want to resize an image to a specific size, we can use tf.image.resize().\n",
    "    new_height = new_width = 32\n",
    "    image = tf.image.resize(image, (new_height, new_width))\n",
    "\n",
    "    # If we want to convert the image to grayscale, we can use tf.image.rgb_to_grayscale()\n",
    "    # 10% chance to convert image to grayscale. So that our model \n",
    "    # can do prediction on grayscale images as well along with color images.\n",
    "    if tf.random.uniform((), minval=0, maxval=1) < 0.1:\n",
    "        # Copy the grayscale channel 3 times so we can concat it back to RGB channels\n",
    "        # so that we can have 3 channels for grayscale image as well to pass it to our model.\n",
    "        image = tf.tile(tf.image.rgb_to_grayscale(image), [1, 1, 3])\n",
    "    \n",
    "\n",
    "    # Random brightness and contrast\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, lower=0.1, upper=0.2)\n",
    "\n",
    "    # a left upside down flipped is still a dog ;)\n",
    "    image = tf.image.random_flip_left_right(image)  # 50%\n",
    "    # image = tf.image.random_flip_up_down(image) #%50%\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# Setup for train dataset\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "# Augment images in parallel using our custom augment function defined above.\n",
    "ds_train = ds_train.map(augment, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "# Setup for test Dataset\n",
    "ds_test = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_test = ds_train.batch(BATCH_SIZE)\n",
    "ds_test = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "\n",
    "# TF >= 2.3.0\n",
    "# We can add data augmentation as part of our model. Not sure it is done while\n",
    "# training the above custom method is done in parallel while the model is training.\n",
    "# Doing it this way, we don't have to do the above custom method but we might loose\n",
    "# some performance.\n",
    "\n",
    "# data_augmentation = keras.Sequential(\n",
    "#     [\n",
    "#         layers.experimental.preprocessing.Resizing(height=32, width=32,),\n",
    "#         layers.experimental.preprocessing.RandomFlip(mode=\"horizontal\"),\n",
    "#         layers.experimental.preprocessing.RandomContrast(factor=0.1,),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input((32, 32, 3)),\n",
    "        # data_augmentation,\n",
    "        layers.Conv2D(4, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.Conv2D(8, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(10),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(3e-4),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 - 30s - loss: 2.0951 - accuracy: 0.2179\n",
      "Epoch 2/5\n",
      "1563/1563 - 4s - loss: 1.9100 - accuracy: 0.3035\n",
      "Epoch 3/5\n",
      "1563/1563 - 3s - loss: 1.7779 - accuracy: 0.3533\n",
      "Epoch 4/5\n",
      "1563/1563 - 4s - loss: 1.6882 - accuracy: 0.3907\n",
      "Epoch 5/5\n",
      "1563/1563 - 4s - loss: 1.6472 - accuracy: 0.4094\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.6219 - accuracy: 0.4207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6219048500061035, 0.4206799864768982]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, epochs=5, verbose=2)\n",
    "model.evaluate(ds_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
