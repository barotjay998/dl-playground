{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Fine Tuning and TensorfFlow Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Tensorflow Hub is a repository of trained machine learning models\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Configure GPU memory growth to be dynamic instead of allocating all memory at once\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "# x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definition\n",
    "\n",
    "### 3.1 Your Own Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2_input (InputLayer)   [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "1875/1875 - 2s - loss: 0.2334 - accuracy: 0.9324\n",
      "Epoch 2/3\n",
      "1875/1875 - 1s - loss: 0.1130 - accuracy: 0.9668\n",
      "Epoch 3/3\n",
      "1875/1875 - 1s - loss: 0.0864 - accuracy: 0.9742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6f9f813b80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This can be any of your own pretrained models folder, or a model\n",
    "# you downloaded from github or anywhere else.\n",
    "model = keras.models.load_model(\"saved_model/\")\n",
    "\n",
    "# You generally do model.summary() to see what the model looks like and\n",
    "# which layers you want. If you want all the layers then you can just use the \n",
    "# whole loaded model and continue training.\n",
    "# But generally when you are doing transfer learning you would want to pick\n",
    "# out a couple of layers from the model.\n",
    "\n",
    "model.summary()  # for finding base input and output layers\n",
    "\n",
    "# We are going to use this model as our base model and make our model on top of it.\n",
    "\n",
    "# Suppose you want to use everything except the last layer in the base model.\n",
    "# Instead of INDEX you can use the layer name as well by \n",
    "# using model.get_layer(\"layer_name\")\n",
    "base_inputs = model.layers[0].input\n",
    "base_output = model.layers[-2].output\n",
    "final_outputs = layers.Dense(10)(base_output)\n",
    "new_model = keras.Model(inputs=base_inputs, outputs=final_outputs)\n",
    "\n",
    "# This model is actually identical to model we loaded \n",
    "# (this is just for demonstration and and not something you would do in practice).\n",
    "print(new_model.summary())\n",
    "\n",
    "\n",
    "# Compile and train the model\n",
    "new_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "new_model.fit(x_train, y_train, batch_size=32, epochs=3, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Pretrained Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Pretrained TensorFlow Hub Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
