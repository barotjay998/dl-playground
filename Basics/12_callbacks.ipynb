{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks with Keras and Writing your own Callbacks\n",
    "\n",
    "Callbacks is the way to customize the behaviour of your model during either training or evaluation. You can use callbacks to get a view on internal states and statistics of the model during training. \n",
    "\n",
    "You can pass a list of callbacks (as the keyword argument callbacks) to the .fit() method of the Sequential or Model classes. The relevant methods of the callbacks will then be called at each stage of the training.\n",
    "\n",
    "We have seen how to save a model, but we have seen it how to do it after the training. Suppose we want to save the model after each epoch. We can do it with a callback. Or save the best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jay/anaconda3/envs/tf/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Configure GPU memory growth to be dynamic instead of allocating all memory at once\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,  # will return tuple (img, label) otherwise dict\n",
    "    with_info=True,  # able to get info about dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# Setup for train dataset\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input((28, 28, 1)),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras has many built-in callbacks, lookup write custom\n",
    "# callbacks tensorflow documentation.\n",
    "save_callback = keras.callbacks.ModelCheckpoint(\n",
    "    \"checkpoint_callback/\", \n",
    "    save_weights_only=True, \n",
    "    monitor=\"train_acc\", \n",
    "    save_best_only=False,\n",
    ")\n",
    "\n",
    "# This callback function is a learning reate scheduler\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"loss\", \n",
    "    factor=0.1, \n",
    "    patience=3, \n",
    "    mode=\"max\", \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "class OurOwnCallback(keras.callbacks.Callback):\n",
    "    # you can also do on_batch_end, check documentation\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # printing logs will show us the keys we can use\n",
    "        # print(logs.keys()) \n",
    "        if logs.get(\"accuracy\") > 1:\n",
    "            print(\"Accuracy over 70%, quitting training\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.01),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 - 7s - loss: 0.1422 - accuracy: 0.9573\n",
      "Epoch 2/10\n",
      "469/469 - 1s - loss: 0.0572 - accuracy: 0.9824\n",
      "Epoch 3/10\n",
      "469/469 - 1s - loss: 0.0342 - accuracy: 0.9890\n",
      "Epoch 4/10\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9923\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 5/10\n",
      "469/469 - 1s - loss: 0.0087 - accuracy: 0.9973\n",
      "Epoch 6/10\n",
      "469/469 - 1s - loss: 0.0042 - accuracy: 0.9991\n",
      "Epoch 7/10\n",
      "469/469 - 1s - loss: 0.0028 - accuracy: 0.9995\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 8/10\n",
      "469/469 - 1s - loss: 0.0019 - accuracy: 0.9998\n",
      "Epoch 9/10\n",
      "469/469 - 1s - loss: 0.0018 - accuracy: 0.9998\n",
      "Epoch 10/10\n",
      "469/469 - 1s - loss: 0.0017 - accuracy: 0.9998\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdc483cd8e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=10,\n",
    "    callbacks=[save_callback, lr_scheduler, OurOwnCallback()],\n",
    "    verbose=2,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
