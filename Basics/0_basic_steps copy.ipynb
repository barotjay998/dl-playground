{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load Model Weights, Serialize Model.\n",
    "\n",
    "\n",
    "Alright, so here have some code which should feel familiar from previous tutorials, here is what we want to cover:\n",
    " 1. How to save and load model weights\n",
    " 2. Save and loading entire model (Serializing model). When we save the entire model it is going to be stored as a data structure, and hence can be loaded on different tensorflow frameworks like tensforflow.js, tensorflow lite etc. You can train the model on your PC and then put in on production on an android app or a web app. Saving the entire model is going to save the following:\n",
    "    - Saves weights\n",
    "    - Model architecture\n",
    "    - Training Configuration (model.compile())\n",
    "    - Optimizer and states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Configure GPU memory growth to be dynamic instead of allocating all memory at once\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28 * 28).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definition\n",
    "### 3.1 Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(10)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(784)\n",
    "x = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10)(x)\n",
    "model2 = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = layers.Dense(64, activation=\"relu\")\n",
    "        self.dense2 = layers.Dense(10)\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        x = tf.nn.relu(self.dense1(input_tensor))\n",
    "        return self.dense2(x)\n",
    "\n",
    "# SavedModel format or HDF5 format\n",
    "model3 = MyModel()\n",
    "\n",
    "# Load the model weights\n",
    "# model.load_weights('checkpoint_folder/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# OR load the entire model, dont need to include the model\n",
    "# code or the compile code.\n",
    "# model = keras.models.load_model('saved_model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/2\n",
      "1875/1875 - 1s - loss: 0.0666 - accuracy: 0.9790\n",
      "Epoch 2/2\n",
      "1875/1875 - 1s - loss: 0.0548 - accuracy: 0.9833\n",
      "Evaluating model...\n",
      "313/313 - 0s - loss: 0.0904 - accuracy: 0.9723\n",
      "Saving model/weights...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=2, verbose=2)\n",
    "\n",
    "print(\"Evaluating model...\")\n",
    "model.evaluate(x_test, y_test, batch_size=32, verbose=2)\n",
    "\n",
    "print(\"Saving model/weights...\")\n",
    "\"\"\"\n",
    "The default format of saving the model is the latest h5 format, in the tensorflow\n",
    "1.0, the default format was HDF5, which needed additional code in the model\n",
    "to save it, like defining get_config and from_config methods. But in new\n",
    "formats it is not needed.\n",
    "\"\"\"\n",
    "model.save_weights('checkpoint_folder/')\n",
    "# model.save(\"saved_model/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
