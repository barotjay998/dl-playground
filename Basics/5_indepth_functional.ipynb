{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports, Configuration and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "# to get current workind directory \n",
    "# Use os.getcwd()\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# Use pandas to load dataset from csv file\n",
    "import pandas as pd\n",
    "\n",
    "# Configure GPU memory growth to be dynamic instead of allocating all memory at once\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "BATCH_SIZE = 64\n",
    "WEIGHT_DECAY = 0.001\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/jay/Dev/datasets/multi_digit_mnist/\"\n",
    "\n",
    "train_df = pd.read_csv(file_path + \"train.csv\")\n",
    "test_df = pd.read_csv(file_path + \"test.csv\")\n",
    "train_images = file_path + \"train_images/\" + train_df.iloc[:, 0].values\n",
    "test_images = file_path + \"test_images/\" + test_df.iloc[:, 0].values\n",
    "\n",
    "train_labels = train_df.iloc[:, 1:].values\n",
    "test_labels = test_df.iloc[:, 1:].values\n",
    "\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def read_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=1, dtype=tf.float32)\n",
    "\n",
    "    # In older versions you need to set shape in order to avoid error\n",
    "    # on newer (2.3.0+) the following 3 lines can safely be removed\n",
    "    image.set_shape((64, 64, 1))\n",
    "    label[0].set_shape([])\n",
    "    label[1].set_shape([])\n",
    "\n",
    "    labels = {\"first_num\": label[0], \"second_num\": label[1]}\n",
    "    return image, labels\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = (\n",
    "    train_dataset.shuffle(buffer_size=len(train_labels))\n",
    "    .map(read_image)\n",
    "    .batch(batch_size=BATCH_SIZE)\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_dataset = (\n",
    "    test_dataset.map(read_image)\n",
    "    .batch(batch_size=BATCH_SIZE)\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definition\n",
    "\n",
    "Sequential can only map from one input to one output, we use functional API to map from multiple inputs to multiple outputs. In this example we will map one input to two outptuts. As out multidigit_mnist dataset has 2 labels for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64 x 64 pixels and 1 channel (grayscale)\n",
    "inputs = keras.Input(shape=(64, 64, 1))\n",
    "x = layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    padding=\"same\",\n",
    "    kernel_regularizer=regularizers.l2(WEIGHT_DECAY),\n",
    ")(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "\n",
    "x = layers.Conv2D(\n",
    "    64, 3, kernel_regularizer=regularizers.l2(WEIGHT_DECAY),\n",
    "    )(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "\n",
    "x = layers.Conv2D(\n",
    "    64, 3, activation=\"relu\", kernel_regularizer=regularizers.l2(WEIGHT_DECAY),\n",
    ")(x)\n",
    "\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "\n",
    "# This is where function API differs from Sequential API, and is useful.\n",
    "output1 = layers.Dense(10, activation=\"softmax\", name=\"first_num\")(x)\n",
    "output2 = layers.Dense(10, activation=\"softmax\", name=\"second_num\")(x)\n",
    "\n",
    "# Model with one input and two outputs\n",
    "model = keras.Model(inputs=inputs, outputs=[output1, output2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compile Model\n",
    "\n",
    "If you specify just one loss that will be assigned to all outputs. If you want to specify different losses for different outputs, you can do it by passing a dictionary individually.\n",
    "In this example we have applied a softmax activation on the output layer hence we dont have to do logits=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(LEARNING_RATE),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training and Evaluation\n",
    "\n",
    "Batch size is taken care of in the dataloading part. We only need to specify the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/5\n",
      "1000/1000 - 25s - loss: 0.2085 - first_num_loss: 0.0849 - second_num_loss: 0.0815 - first_num_accuracy: 0.9731 - second_num_accuracy: 0.9727\n",
      "Epoch 2/5\n",
      "1000/1000 - 25s - loss: 0.1838 - first_num_loss: 0.0724 - second_num_loss: 0.0717 - first_num_accuracy: 0.9765 - second_num_accuracy: 0.9763\n",
      "Epoch 3/5\n",
      "1000/1000 - 25s - loss: 0.1724 - first_num_loss: 0.0690 - second_num_loss: 0.0649 - first_num_accuracy: 0.9777 - second_num_accuracy: 0.9785\n",
      "Epoch 4/5\n",
      "1000/1000 - 25s - loss: 0.1599 - first_num_loss: 0.0635 - second_num_loss: 0.0591 - first_num_accuracy: 0.9798 - second_num_accuracy: 0.9795\n",
      "Epoch 5/5\n",
      "1000/1000 - 25s - loss: 0.1454 - first_num_loss: 0.0559 - second_num_loss: 0.0544 - first_num_accuracy: 0.9822 - second_num_accuracy: 0.9818\n",
      "Evaluating model...\n",
      "Test loss, test acc: 1.0477\n",
      "First number loss: 0.3249\n",
      "Second number loss: 0.6882\n",
      "First number accuracy: 0.9139\n",
      "Second number accuracy: 0.8392\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "model.fit(train_dataset, epochs=5, verbose=2)\n",
    "\n",
    "print(\"Evaluating model...\")\n",
    "results = model.evaluate(test_dataset, verbose=0)\n",
    "print(f\"Test loss, test acc: {results[0]:.4f}\")\n",
    "print(f\"First number loss: {results[1]:.4f}\")\n",
    "print(f\"Second number loss: {results[2]:.4f}\")\n",
    "print(f\"First number accuracy: {results[3]:.4f}\")\n",
    "print(f\"Second number accuracy: {results[4]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
