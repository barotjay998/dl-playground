{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jay/anaconda3/envs/tf/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import io\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Make sure we don't get any GPU errors\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    \"cifar10\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "\n",
    "def augment(image, label):\n",
    "    if tf.random.uniform((), minval=0, maxval=1) < 0.1:\n",
    "        image = tf.tile(tf.image.rgb_to_grayscale(image), [1, 1, 3])\n",
    "\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Setup for train dataset\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "ds_train = ds_train.map(augment)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "# Setup for test Dataset\n",
    "ds_test = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_test = ds_train.batch(BATCH_SIZE)\n",
    "ds_test = ds_train.prefetch(AUTOTUNE)\n",
    "\n",
    "class_names = [\n",
    "    \"Airplane\",\n",
    "    \"Autmobile\",\n",
    "    \"Bird\",\n",
    "    \"Cat\",\n",
    "    \"Deer\",\n",
    "    \"Dog\",\n",
    "    \"Frog\",\n",
    "    \"Horse\",\n",
    "    \"Ship\",\n",
    "    \"Truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Input((32, 32, 3)),\n",
    "            layers.Conv2D(8, 3, padding=\"same\", activation=\"relu\"),\n",
    "            layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            layers.Dropout(0.1),\n",
    "            layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 12:32:33.139403: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 12:32:44.322337: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1415] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 - 26s - loss: 1.6104 - accuracy: 0.4124 - val_loss: 1.3187 - val_accuracy: 0.5280\n",
      "Epoch 2/5\n",
      "1563/1563 - 8s - loss: 1.3163 - accuracy: 0.5268 - val_loss: 1.1975 - val_accuracy: 0.5798\n",
      "Epoch 3/5\n",
      "1563/1563 - 9s - loss: 1.2065 - accuracy: 0.5701 - val_loss: 1.0765 - val_accuracy: 0.6211\n",
      "Epoch 4/5\n",
      "1563/1563 - 8s - loss: 1.1398 - accuracy: 0.5951 - val_loss: 1.0342 - val_accuracy: 0.6376\n",
      "Epoch 5/5\n",
      "1563/1563 - 9s - loss: 1.0919 - accuracy: 0.6136 - val_loss: 0.9976 - val_accuracy: 0.6531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4212d6fdf0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Tensorboard Callback:\n",
    "Is a callback that writes logs for TensorBoard, which allows you to visualize\n",
    "dynamic graphs of your training and test metrics, as well as activation histograms\n",
    "for the different layers in your model.\n",
    "\n",
    ":param log_dir: the path of the directory where to save the log files to be\n",
    ":param histogram_freq: frequency (in epochs) at which to compute activation\n",
    "\"\"\"\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"tb_callback_dir\", histogram_freq=1,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=5,\n",
    "    validation_data=ds_test,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    verbose=2,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
